{
  "cells": [
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "# Question Answering System"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "##### Importing libraries"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#for webpage and snippet extraction\nimport urllib\nimport requests\nfrom bs4 import BeautifulSoup\nfrom requests import get\nimport re\nimport collections\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\n\n#for answer filtering\nimport io\nimport random\nimport string # to process standard python strings\nimport warnings\nimport numpy as np\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom nltk.stem import WordNetLemmatizer\nnltk.download('popular', quiet=True)\nnltk.download('punkt')\nnltk.download('wordnet')",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[nltk_data] Downloading package stopwords to /home/nbuser/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package punkt to /home/nbuser/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package wordnet to /home/nbuser/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "True"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)",
      "execution_count": 14,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# For Keyword Matching\nGREETING_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\",\"hey\",)\nGREETING_RESPONSES = [\"hi\", \"hey\", \"*nods*\", \"hi there\", \"hello\", \"I am glad! You are talking to me\"]",
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Web Page Extraction"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def webpageextraction(query):\n    query=query.replace(' ','+')\n    URL = f\"https://google.com/search?q={query}\"\n    ## user agent specification, as google returns different results for mobile and desktop\n    ### desktop user-agent\n    USER_AGENT = \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.14; rv:65.0) Gecko/20100101 Firefox/65.0\"\n    ### mobile user-agent\n    MOBILE_USER_AGENT = \"Mozilla/5.0 (Linux; Android 7.0; SM-G930V Build/NRD90M) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.125 Mobile Safari/537.36\"\n\n    ## user-agent must be in the headers. We pass in a dictionary for the headers in requests.\n    headers = {\"user-agent\" : USER_AGENT}\n    response = requests.get(URL, headers=headers)\n\n    ## checking if the request was successful (if we obtain 200 in return, it is successful), then we put it into BeautifulSoup for content parsing\n    if response.status_code == 200:\n        soup = BeautifulSoup(response.content, \"html.parser\")\n\n    ## parsing the data and extracting all anchor links from the page. storing the results in the results list.\n    results = []\n    for g in soup.find_all('div', class_='r'):\n        anchors = g.find_all('a')\n        if anchors:\n            link = anchors[0]['href']\n            title = g.find('h3').text\n            item = {\n                \"title\": title,\n                \"link\": link\n            }\n            results.append(item['link'])\n    return results",
      "execution_count": 22,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Snippet Extraction"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def snippetextraction(results,i):\n    # Snippet Extraction from the obtained web page urls\n    try:\n        raw = get(results[i]).text ###this is how we can extract raw html from web pages\n    except:\n        return 'error604'\n    html = requests.get(results[i]).content\n    #1 Recoding\n    unicode_str = html.decode(\"utf8\")\n    encoded_str = unicode_str.encode(\"ascii\",'ignore')\n    news_soup = BeautifulSoup(encoded_str, \"html.parser\")\n    a_text = news_soup.find_all('p')\n    #2 Removing\n    y=[re.sub(r'<.+?>',r'',str(a)) for a in a_text]\n    y=[x.replace('\\n','') for x in y]\n    y=[x.strip() for x in y]\n    y=' '.join(y)\n    return y",
      "execution_count": 60,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Tokenisation"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def tokenise(raw):\n    #Tokenisation\n    sent_tokens = nltk.sent_tokenize(raw)# converts to list of sentences \n    #print(sent_tokens)\n    word_tokens = nltk.word_tokenize(raw)# converts to list of words\n    return sent_tokens",
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Preprocessing"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def LemTokens(tokens):\n    lemmer = WordNetLemmatizer()\n    return [lemmer.lemmatize(token) for token in tokens]\nremove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\ndef LemNormalize(text):\n    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))",
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Generating Response"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def response(query,sent_tokens):\n    robo_response=''\n    sent_tokens.append(query)\n    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n    tfidf = TfidfVec.fit_transform(sent_tokens)\n    vals = cosine_similarity(tfidf[-1], tfidf)\n    idx=vals.argsort()[0][-2]\n    flat = vals.flatten()\n    flat.sort()\n    req_tfidf = flat[-2]\n    if(req_tfidf==0):\n        robo_response=robo_response+\"I am sorry! I don't understand you\"\n        print(robo_response)\n        return 'error502'\n    else:\n        robo_response = robo_response+sent_tokens[idx]\n        return robo_response",
      "execution_count": 66,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Edulexa Greeting & Bye"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# for greeting the user\ndef greeting(query):\n    \"\"\"If user's input is a greeting, return a greeting response\"\"\"\n    for word in query.split():\n        if word.lower() in GREETING_INPUTS:\n            return random.choice(GREETING_RESPONSES)\n        \n# for saying bye and ending the program\ndef byee():\n    print(\"Edulexa: Bye! take care..\")\n    return False\n\n#for setting flag to true and introduction\ndef introduce():\n    #as we are taking a variable flag (true until user keeps asking questions)\n    print(\"Edulexa: Hi! My name is Edulexa. I will answer all your queries. If you want to exit, type something like 'Bye' !\")\n    return True",
      "execution_count": 57,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Final Operation"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Edulexa introduces itself\nflag=introduce()\n#site index\nprint('May I know your name?')\n#User introduces\nuser_name=input()\nprint('Edulexa: Hello ',user_name)\n\nwhile(flag==True):\n    i=0\n    #taking user question\n    query = input(user_name+': ')\n    query=query.lower()\n    \n    if('bye' not in query.split(' ')):\n        if(query=='thanks' or query=='thank you' ):\n            flag=False\n            print(\"Edulexa: You are welcome..\")\n        else:\n            if(greeting(query)!=None):\n                print(\"Edulexa: \"+greeting(query))\n            else:\n                result=webpageextraction(query)\n                raw=''\n                while((not raw.strip()) or (('access' in raw.lower()) and ('denied' in raw.lower()))):\n                    raw=snippetextraction(result,i)\n                    if raw=='error604':\n                        break\n                    i+=1\n                if raw=='error604':\n                    print(\"Sorry I couldn't find an answer.\")\n                    continue\n                if raw:\n                    sent_tokens=tokenise(raw)\n                else:\n                    print(\"Sorry I couldn't find an answer.\")\n                print(\"Edulexa: \",end='')\n                answer=response(query,sent_tokens)\n                if answer=='error502':\n                    continue\n                print(answer)\n                \n                \n                #now checking satisfaction\n                satisfied=False\n                while(not satisfied):\n                    print('Are you satisfied by my answer? Enter \"yes\" or \"no\".')\n                    if (input().lower()=='yes'):\n                        break\n                    else:\n                        i+=1\n                        raw=snippetextraction(result,i)\n                        while((not raw.strip()) or (('access' in raw.lower()) and ('denied' in raw.lower()))):\n                            raw=snippetextraction(result,i)\n                            i+=1\n                        if raw=='error604':\n                            print('Sorry, I am out of answers now.')\n                            print(\"Anything else you would like to ask?\")\n                            break\n                        if raw:\n                            sent_tokens=tokenise(raw)\n                        else:\n                            print(\"Sorry I couldn't find an answer.\")\n                        print(\"Edulexa: \",end='')\n                        print(response(query,sent_tokens))\n                        \n                    \n                sent_tokens.remove(query)\n                \n    elif ('bye' in query.split(' ')):\n        flag=False\n        byee()",
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Edulexa: Hi! My name is Edulexa. I will answer all your queries. If you want to exit, type something like 'Bye' !\nMay I know your name?\nSaloni\nEdulexa: Hello  Saloni\nSaloni: what's in a name?\nEdulexa: I am sorry! I don't understand you\nSaloni: How is gold?\nEdulexa: Of course, here at Scottsdale Bullion and Coin, we can help you find all the gold that you want, whether its in the form of gold bullion bars or numismatic gold coins.\nAre you satisfied by my answer? Enter \"yes\" or \"no\".\nno\nEdulexa: But there was still no gold in the Universe.\nAre you satisfied by my answer? Enter \"yes\" or \"no\".\nno\nEdulexa: It is the modern gold pan method used in the gold rush.\nAre you satisfied by my answer? Enter \"yes\" or \"no\".\nno\nEdulexa: While transmuting mercury into gold is easiest, gold can be made from other elementseven lead!\nAre you satisfied by my answer? Enter \"yes\" or \"no\".\nyes\nSaloni: what is mercury?\nEdulexa: Mercury poisoning can result from exposure to water-soluble forms of mercury (such as mercuric chloride or methylmercury), by inhalation of mercury vapor, or by ingesting any form of mercury.\nAre you satisfied by my answer? Enter \"yes\" or \"no\".\nno\nEdulexa: When mercury comes into contact with gold, the gold dissolves into the mercury and then the two are separated, with the mercury being distilled off.\nAre you satisfied by my answer? Enter \"yes\" or \"no\".\nyes\nSaloni: what is electromagnet?\nEdulexa: What is an electromagnet?\nAre you satisfied by my answer? Enter \"yes\" or \"no\".\nno\nEdulexa: Mechanically, an electromagnet is pretty simple.\nAre you satisfied by my answer? Enter \"yes\" or \"no\".\nno\nEdulexa: Keep scrolling for more More Definitions for electromagnet   electromagnet noun  English Language Learners Definition of electromagnet : a piece of metal that becomes magnetic when an electric current is passed through or near it See the full definition for electromagnet in the English Language Learners Dictionary   electromagnet noun elec​tro​mag​net | \\ i-lek-tr-mag-nt  \\ Kids Definition of electromagnet : a piece of iron encircled by a coil of wire through which an electric current is passed to magnetize the iron   electromagnet noun elec​tro​mag​net | \\ i-lek-tr-mag-nt  \\ Medical Definition of electromagnet : a core of magnetic material surrounded by a coil of wire through which an electric current is passed to magnetize the core electromagnet  See the full definition for electromagnet in the English Language Learners Dictionary electromagnet  electromagnet  Keep scrolling for more More from Merriam-Webster on electromagnet Spanish Central: Translation of electromagnet Nglish: Translation of electromagnet for Spanish Speakers Britannica.com: Encyclopedia article about electromagnet Spanish Central: Translation of electromagnet Nglish: Translation of electromagnet for Spanish Speakers Britannica.com: Encyclopedia article about electromagnet Nglish: Translation of electromagnet for Spanish Speakers Britannica.com: Encyclopedia article about electromagnet Britannica.com: Encyclopedia article about electromagnet Comments on electromagnet What made you want to look up electromagnet?\nAre you satisfied by my answer? Enter \"yes\" or \"no\".\nno\nEdulexa: Electromagnets are widely used in common electrical systems.\nAre you satisfied by my answer? Enter \"yes\" or \"no\".\nno\nEdulexa: The engineering design of electromagnets is systematized by means of the concept of the magnetic circuit.\nAre you satisfied by my answer? Enter \"yes\" or \"no\".\nno\nEdulexa: When the electrical current is active, the electromagnet produces a magnetic field.\nAre you satisfied by my answer? Enter \"yes\" or \"no\".\nno\nSorry, I am out of answers now.\nAnything else you would like to ask?\nSaloni: Where is Delhi?\nEdulexa: The main railway stations are New Delhi, Old Delhi, Hazrat Nizamuddin, Anand Vihar, Delhi Sarai Rohilla and Delhi Cantt.\nAre you satisfied by my answer? Enter \"yes\" or \"no\".\nno\nEdulexa: The city of Delhi actually consists of two components: Old Delhi, in the north, the historic city; and New Delhi, in the south, since 1947 the capital of India, built in the first part of the 20th century as the capital of British India.\nAre you satisfied by my answer? Enter \"yes\" or \"no\".\nyes\nSaloni: Okay bye\nEdulexa: Bye! take care..\n",
          "name": "stdout"
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}